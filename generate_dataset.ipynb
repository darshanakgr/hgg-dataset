{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_files = glob.glob(\"data/captions/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([]).reshape(0, 1561)\n",
    "y = np.array([]).reshape(0, 84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [06:16<00:00,  6.49s/it]\n"
     ]
    }
   ],
   "source": [
    "for caption_file in tqdm.tqdm(caption_files):\n",
    "    \n",
    "    video_id = caption_file.split(\"/\")[-1].replace(\".csv\", \"\")\n",
    "    text_feature_file = f\"data/features/text/{video_id}.npy\"\n",
    "\n",
    "    captions = pd.read_csv(caption_file)\n",
    "\n",
    "    text_features = np.load(text_feature_file)\n",
    "\n",
    "    for i in range(len(captions)):\n",
    "        t, d = captions.iloc[i, [0, 1]]\n",
    "\n",
    "        audio_feature_file = f\"data/features/audio/{video_id}/audio_feat_{t}_{d}.npy\"\n",
    "        hand_pose_file = f\"data/features/handpose/{video_id}/handpose_{t}_{d}.npy\"\n",
    "\n",
    "        if os.path.exists(audio_feature_file):\n",
    "            audio_features = np.load(audio_feature_file)\n",
    "            \n",
    "            if os.path.exists(hand_pose_file) and os.path.getsize(hand_pose_file) > 278:\n",
    "                hand_poses = np.load(hand_pose_file, allow_pickle=True)\n",
    "                \n",
    "                x1 = audio_features.reshape(audio_features.shape[0], -1)\n",
    "                x2 = text_features[i].reshape(1, -1).repeat(audio_features.shape[0], axis=0)\n",
    "                \n",
    "                x = np.concatenate((x, np.append(x1, x2, axis=1)), axis=0)\n",
    "                y = np.concatenate((y, hand_poses), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"data/dataset.npz\", x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99709, 1561), (99709, 84))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81728513bbe5f74440b07cc41ab2f77162a75fab4bcd848c59f902a39c1a9d15"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
